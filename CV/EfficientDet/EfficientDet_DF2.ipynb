{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EfficientDet building for DF2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connecting to DF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import os\n",
    "import pandas as pd\n",
    "import json, csv\n",
    "import matplotlib.image as img\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up connection to DF2 bucket\n",
    "bucket = 'descriptiveworld-datasets'\n",
    "subfolder = 'DeepFashion2/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker import get_execution_role\n",
    "role = get_execution_role()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ClientError",
     "evalue": "An error occurred (AccessDenied) when calling the ListObjects operation: Access Denied",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mClientError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-868e786c1d68>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mconn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mboto3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m's3'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mcontents\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlist_objects\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBucket\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbucket\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPrefix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msubfolder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Contents'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcontents\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Key'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/amazonei_tensorflow2_p36/lib/python3.6/site-packages/botocore/client.py\u001b[0m in \u001b[0;36m_api_call\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    384\u001b[0m                     \"%s() only accepts keyword arguments.\" % py_operation_name)\n\u001b[1;32m    385\u001b[0m             \u001b[0;31m# The \"self\" in this scope is referring to the BaseClient.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 386\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_api_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moperation_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    387\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    388\u001b[0m         \u001b[0m_api_call\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpy_operation_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/amazonei_tensorflow2_p36/lib/python3.6/site-packages/botocore/client.py\u001b[0m in \u001b[0;36m_make_api_call\u001b[0;34m(self, operation_name, api_params)\u001b[0m\n\u001b[1;32m    703\u001b[0m             \u001b[0merror_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsed_response\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Error\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Code\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m             \u001b[0merror_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_code\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 705\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0merror_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparsed_response\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moperation_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    706\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    707\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mparsed_response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mClientError\u001b[0m: An error occurred (AccessDenied) when calling the ListObjects operation: Access Denied"
     ]
    }
   ],
   "source": [
    "conn = boto3.client('s3')\n",
    "contents = conn.list_objects(Bucket=bucket, Prefix=subfolder)['Contents']\n",
    "for f in contents:\n",
    "    print(f['Key'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing json for training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/ec2-user/SageMaker'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# orig_file = 'DeepFashion2/train/train.json'\n",
    "# dest_file = '/home/ec2-user/SageMaker/train.json'\n",
    "\n",
    "# # Connect to S3 bucket and download file - train.json\n",
    "# s3 = boto3.resource('s3')\n",
    "# s3.Bucket(bucket).download_file(orig_file, dest_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading in json\n",
    "train_df = pd.read_json(\"train.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item2</th>\n",
       "      <th>source</th>\n",
       "      <th>pair_id</th>\n",
       "      <th>item3</th>\n",
       "      <th>item4</th>\n",
       "      <th>item6</th>\n",
       "      <th>item5</th>\n",
       "      <th>item8</th>\n",
       "      <th>item7</th>\n",
       "      <th>img</th>\n",
       "      <th>segmentation</th>\n",
       "      <th>scale</th>\n",
       "      <th>viewpoint</th>\n",
       "      <th>zoom_in</th>\n",
       "      <th>landmarks</th>\n",
       "      <th>style</th>\n",
       "      <th>bounding_box</th>\n",
       "      <th>category_id</th>\n",
       "      <th>occlusion</th>\n",
       "      <th>category_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'segmentation': [[460, 438, 374, 484, 251, 52...</td>\n",
       "      <td>user</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>000001.jpg</td>\n",
       "      <td>[[257, 35, 261, 89, 228, 123, 137, 103, 45, 91...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>[182, 54, 1, 45, 91, 1, 137, 103, 1, 228, 123,...</td>\n",
       "      <td>1</td>\n",
       "      <td>[0, 29, 466, 622]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>short sleeve top</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'segmentation': [[220.25, 187.55, 259.6, 177....</td>\n",
       "      <td>shop</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>000002.jpg</td>\n",
       "      <td>[[145.21, 314.0, 162.67, 312.8, 175.12, 313.05...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>[127, 335, 1, 73, 340, 1, 107, 354, 1, 140, 35...</td>\n",
       "      <td>1</td>\n",
       "      <td>[1, 300, 367, 701]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>short sleeve top</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>None</td>\n",
       "      <td>user</td>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>000003.jpg</td>\n",
       "      <td>[[338, 64, 299, 133, 228, 189, 183, 121, 160, ...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>[240, 108, 2, 160, 63, 2, 183, 121, 2, 228, 18...</td>\n",
       "      <td>1</td>\n",
       "      <td>[1, 52, 467, 831]</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>long sleeve dress</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>None</td>\n",
       "      <td>user</td>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>000004.jpg</td>\n",
       "      <td>[[266, 160, 257, 191, 233, 218, 184, 210, 149,...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>[223, 187, 1, 149, 190, 2, 184, 210, 2, 233, 2...</td>\n",
       "      <td>1</td>\n",
       "      <td>[0, 113, 467, 623]</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>long sleeve dress</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>None</td>\n",
       "      <td>user</td>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>000005.jpg</td>\n",
       "      <td>[[204.0, 143.0, 182.0, 137.0, 167.0, 130.0, 16...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>[205, 143, 2, 162, 129, 2, 192, 164, 2, 222, 1...</td>\n",
       "      <td>1</td>\n",
       "      <td>[1, 98, 467, 814]</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>long sleeve dress</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               item2 source  pair_id item3  \\\n",
       "0  {'segmentation': [[460, 438, 374, 484, 251, 52...   user        1  None   \n",
       "1  {'segmentation': [[220.25, 187.55, 259.6, 177....   shop        1  None   \n",
       "2                                               None   user        2  None   \n",
       "3                                               None   user        2  None   \n",
       "4                                               None   user        2  None   \n",
       "\n",
       "  item4 item6 item5 item8 item7         img  \\\n",
       "0  None  None  None  None  None  000001.jpg   \n",
       "1  None  None  None  None  None  000002.jpg   \n",
       "2  None  None  None  None  None  000003.jpg   \n",
       "3  None  None  None  None  None  000004.jpg   \n",
       "4  None  None  None  None  None  000005.jpg   \n",
       "\n",
       "                                        segmentation  scale  viewpoint  \\\n",
       "0  [[257, 35, 261, 89, 228, 123, 137, 103, 45, 91...      3          2   \n",
       "1  [[145.21, 314.0, 162.67, 312.8, 175.12, 313.05...      3          2   \n",
       "2  [[338, 64, 299, 133, 228, 189, 183, 121, 160, ...      3          1   \n",
       "3  [[266, 160, 257, 191, 233, 218, 184, 210, 149,...      3          2   \n",
       "4  [[204.0, 143.0, 182.0, 137.0, 167.0, 130.0, 16...      3          1   \n",
       "\n",
       "   zoom_in                                          landmarks  style  \\\n",
       "0        2  [182, 54, 1, 45, 91, 1, 137, 103, 1, 228, 123,...      1   \n",
       "1        2  [127, 335, 1, 73, 340, 1, 107, 354, 1, 140, 35...      1   \n",
       "2        2  [240, 108, 2, 160, 63, 2, 183, 121, 2, 228, 18...      1   \n",
       "3        2  [223, 187, 1, 149, 190, 2, 184, 210, 2, 233, 2...      1   \n",
       "4        2  [205, 143, 2, 162, 129, 2, 192, 164, 2, 222, 1...      1   \n",
       "\n",
       "         bounding_box  category_id  occlusion      category_name  \n",
       "0   [0, 29, 466, 622]            1          2   short sleeve top  \n",
       "1  [1, 300, 367, 701]            1          2   short sleeve top  \n",
       "2   [1, 52, 467, 831]           11          1  long sleeve dress  \n",
       "3  [0, 113, 467, 623]           11          1  long sleeve dress  \n",
       "4   [1, 98, 467, 814]           11          1  long sleeve dress  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img</th>\n",
       "      <th>category_name</th>\n",
       "      <th>bounding_box</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000001.jpg</td>\n",
       "      <td>short sleeve top</td>\n",
       "      <td>[0, 29, 466, 622]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000002.jpg</td>\n",
       "      <td>short sleeve top</td>\n",
       "      <td>[1, 300, 367, 701]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000003.jpg</td>\n",
       "      <td>long sleeve dress</td>\n",
       "      <td>[1, 52, 467, 831]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000004.jpg</td>\n",
       "      <td>long sleeve dress</td>\n",
       "      <td>[0, 113, 467, 623]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000005.jpg</td>\n",
       "      <td>long sleeve dress</td>\n",
       "      <td>[1, 98, 467, 814]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          img      category_name        bounding_box\n",
       "0  000001.jpg   short sleeve top   [0, 29, 466, 622]\n",
       "1  000002.jpg   short sleeve top  [1, 300, 367, 701]\n",
       "2  000003.jpg  long sleeve dress   [1, 52, 467, 831]\n",
       "3  000004.jpg  long sleeve dress  [0, 113, 467, 623]\n",
       "4  000005.jpg  long sleeve dress   [1, 98, 467, 814]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Making a subset of the dataframe for testing\n",
    "train_columns = ['img', 'category_name', \"bounding_box\"]\n",
    "train_sub = train_df.loc[:, train_columns]\n",
    "train_sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "category_name\n",
       "long sleeve top       25085\n",
       "short sleeve dress    16706\n",
       "short sleeve top      53914\n",
       "trousers              23250\n",
       "Name: img, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Testing only a handfull of labels\n",
    "short_list = ['short sleeve top', 'trousers', 'long sleeve top', 'short sleeve dress']\n",
    "train_short = train_sub[train_sub.category_name.isin(short_list)]\n",
    "train_short.groupby('category_name').count()['img']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing training images by making folders on local drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('effdet_df2'):\n",
    "    os.mkdir('effdet_df2')\n",
    "if not os.path.exists('effdet_df2/train'):\n",
    "    os.mkdir('effdet_df2/train')\n",
    "if not os.path.exists('effdet_df2/val'):\n",
    "    os.mkdir('effdet_df2/val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img</th>\n",
       "      <th>bounding_box</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>category_name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>long sleeve top</th>\n",
       "      <td>5000</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>short sleeve dress</th>\n",
       "      <td>5000</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>short sleeve top</th>\n",
       "      <td>5000</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trousers</th>\n",
       "      <td>5000</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     img  bounding_box\n",
       "category_name                         \n",
       "long sleeve top     5000          5000\n",
       "short sleeve dress  5000          5000\n",
       "short sleeve top    5000          5000\n",
       "trousers            5000          5000"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_short_sub = train_short.groupby('category_name').sample(n=5000, random_state=5)\n",
    "train_short_sub.groupby('category_name').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img</th>\n",
       "      <th>category_name</th>\n",
       "      <th>bounding_box</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22276</th>\n",
       "      <td>022277.jpg</td>\n",
       "      <td>long sleeve top</td>\n",
       "      <td>[217, 32, 614, 342]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7026</th>\n",
       "      <td>007027.jpg</td>\n",
       "      <td>long sleeve top</td>\n",
       "      <td>[192, 311, 605, 771]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102933</th>\n",
       "      <td>102935.jpg</td>\n",
       "      <td>long sleeve top</td>\n",
       "      <td>[152, 135, 592, 393]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23657</th>\n",
       "      <td>023658.jpg</td>\n",
       "      <td>long sleeve top</td>\n",
       "      <td>[11, 0, 463, 824]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149394</th>\n",
       "      <td>149403.jpg</td>\n",
       "      <td>long sleeve top</td>\n",
       "      <td>[87, 169, 173, 232]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               img    category_name          bounding_box\n",
       "22276   022277.jpg  long sleeve top   [217, 32, 614, 342]\n",
       "7026    007027.jpg  long sleeve top  [192, 311, 605, 771]\n",
       "102933  102935.jpg  long sleeve top  [152, 135, 592, 393]\n",
       "23657   023658.jpg  long sleeve top     [11, 0, 463, 824]\n",
       "149394  149403.jpg  long sleeve top   [87, 169, 173, 232]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_short_sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['022277.jpg', '007027.jpg', '102935.jpg', '023658.jpg', '149403.jpg']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_list = list(train_short_sub['img'])\n",
    "train_list[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # transferring images from s3 to local\n",
    "# s3 = boto3.resource('s3')\n",
    "\n",
    "# for image in train_list:\n",
    "#     orig_img = 'DeepFashion2/train/image/' + image\n",
    "#     dest_img = '/home/ec2-user/SageMaker/effdet_df2/train/' + image\n",
    "    \n",
    "#     # Connect to S3 bucket and download image\n",
    "#     s3.Bucket(bucket).download_file(orig_img, dest_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20000\n"
     ]
    }
   ],
   "source": [
    "temp_list = os.listdir('./effdet_df2/train')\n",
    "print(len(temp_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up dataset for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img</th>\n",
       "      <th>category_name</th>\n",
       "      <th>x1</th>\n",
       "      <th>y1</th>\n",
       "      <th>x2</th>\n",
       "      <th>y2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22276</th>\n",
       "      <td>022277.jpg</td>\n",
       "      <td>long sleeve top</td>\n",
       "      <td>217</td>\n",
       "      <td>32</td>\n",
       "      <td>614</td>\n",
       "      <td>342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7026</th>\n",
       "      <td>007027.jpg</td>\n",
       "      <td>long sleeve top</td>\n",
       "      <td>192</td>\n",
       "      <td>311</td>\n",
       "      <td>605</td>\n",
       "      <td>771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102933</th>\n",
       "      <td>102935.jpg</td>\n",
       "      <td>long sleeve top</td>\n",
       "      <td>152</td>\n",
       "      <td>135</td>\n",
       "      <td>592</td>\n",
       "      <td>393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23657</th>\n",
       "      <td>023658.jpg</td>\n",
       "      <td>long sleeve top</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>463</td>\n",
       "      <td>824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149394</th>\n",
       "      <td>149403.jpg</td>\n",
       "      <td>long sleeve top</td>\n",
       "      <td>87</td>\n",
       "      <td>169</td>\n",
       "      <td>173</td>\n",
       "      <td>232</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               img    category_name   x1   y1   x2   y2\n",
       "22276   022277.jpg  long sleeve top  217   32  614  342\n",
       "7026    007027.jpg  long sleeve top  192  311  605  771\n",
       "102933  102935.jpg  long sleeve top  152  135  592  393\n",
       "23657   023658.jpg  long sleeve top   11    0  463  824\n",
       "149394  149403.jpg  long sleeve top   87  169  173  232"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Making columns for the bounding box coordinates\n",
    "train_short_sub[['x1', 'y1', 'x2', 'y2']] = pd.DataFrame(\n",
    "    train_short_sub.bounding_box.tolist(), index=train_short_sub.index)\n",
    "train_short_sub.drop(columns=[\"bounding_box\"], inplace=True)\n",
    "train_short_sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# determine the dimensions of each image\n",
    "dims = []\n",
    "for file in list(train_short_sub['img']):\n",
    "    i = Image.open('./effdet_df2/train/'+file)\n",
    "    dims.append([*i.size])\n",
    "dims_df = pd.DataFrame(dims, columns=['i_w', 'i_h'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      i_h\n",
      "i_w      \n",
      "468  7471\n",
      "      i_w\n",
      "i_h      \n",
      "624  2697\n"
     ]
    }
   ],
   "source": [
    "most_common_w = dims_df.groupby('i_w').count().sort_values(by='i_h', ascending=False).iloc[:1]\n",
    "most_common_h = dims_df.groupby('i_h').count().sort_values(by='i_w', ascending=False).iloc[:1]\n",
    "print(most_common_w)\n",
    "print(most_common_h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_short_sub = pd.concat([train_short_sub.reset_index(drop=True), dims_df.reset_index(drop=True)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_DIM = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "373\n"
     ]
    }
   ],
   "source": [
    "# determine which images are outside the range of the image dim\n",
    "toosmall = train_short_sub[(train_short_sub['i_w'] < IMG_DIM) | (train_short_sub['i_h'] < IMG_DIM)]\n",
    "print(len(toosmall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img</th>\n",
       "      <th>category_name</th>\n",
       "      <th>x1</th>\n",
       "      <th>y1</th>\n",
       "      <th>x2</th>\n",
       "      <th>y2</th>\n",
       "      <th>i_w</th>\n",
       "      <th>i_h</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>022277.jpg</td>\n",
       "      <td>long sleeve top</td>\n",
       "      <td>217</td>\n",
       "      <td>32</td>\n",
       "      <td>614</td>\n",
       "      <td>342</td>\n",
       "      <td>687</td>\n",
       "      <td>621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>007027.jpg</td>\n",
       "      <td>long sleeve top</td>\n",
       "      <td>192</td>\n",
       "      <td>311</td>\n",
       "      <td>605</td>\n",
       "      <td>771</td>\n",
       "      <td>750</td>\n",
       "      <td>1125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>102935.jpg</td>\n",
       "      <td>long sleeve top</td>\n",
       "      <td>152</td>\n",
       "      <td>135</td>\n",
       "      <td>592</td>\n",
       "      <td>393</td>\n",
       "      <td>750</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>023658.jpg</td>\n",
       "      <td>long sleeve top</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>463</td>\n",
       "      <td>824</td>\n",
       "      <td>468</td>\n",
       "      <td>832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>138296.jpg</td>\n",
       "      <td>long sleeve top</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>466</td>\n",
       "      <td>623</td>\n",
       "      <td>468</td>\n",
       "      <td>624</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          img    category_name   x1   y1   x2   y2  i_w   i_h\n",
       "0  022277.jpg  long sleeve top  217   32  614  342  687   621\n",
       "1  007027.jpg  long sleeve top  192  311  605  771  750  1125\n",
       "2  102935.jpg  long sleeve top  152  135  592  393  750   500\n",
       "3  023658.jpg  long sleeve top   11    0  463  824  468   832\n",
       "5  138296.jpg  long sleeve top    0    4  466  623  468   624"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Removing small images\n",
    "train_short_sub = train_short_sub[~train_short_sub.img.isin(toosmall.img)]\n",
    "train_short_sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "category_name\n",
       "long sleeve top       4907\n",
       "short sleeve dress    4851\n",
       "short sleeve top      4906\n",
       "trousers              4963\n",
       "Name: img, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_short_sub.groupby('category_name').count()['img']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img</th>\n",
       "      <th>category_name</th>\n",
       "      <th>x1</th>\n",
       "      <th>y1</th>\n",
       "      <th>x2</th>\n",
       "      <th>y2</th>\n",
       "      <th>i_w</th>\n",
       "      <th>i_h</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3040</th>\n",
       "      <td>092400.jpg</td>\n",
       "      <td>long sleeve top</td>\n",
       "      <td>221</td>\n",
       "      <td>357</td>\n",
       "      <td>525</td>\n",
       "      <td>691</td>\n",
       "      <td>750</td>\n",
       "      <td>1125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3608</th>\n",
       "      <td>142068.jpg</td>\n",
       "      <td>long sleeve top</td>\n",
       "      <td>0</td>\n",
       "      <td>91</td>\n",
       "      <td>375</td>\n",
       "      <td>682</td>\n",
       "      <td>424</td>\n",
       "      <td>756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>513</th>\n",
       "      <td>128992.jpg</td>\n",
       "      <td>long sleeve top</td>\n",
       "      <td>319</td>\n",
       "      <td>177</td>\n",
       "      <td>624</td>\n",
       "      <td>506</td>\n",
       "      <td>750</td>\n",
       "      <td>588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2595</th>\n",
       "      <td>121091.jpg</td>\n",
       "      <td>long sleeve top</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>510</td>\n",
       "      <td>502</td>\n",
       "      <td>640</td>\n",
       "      <td>640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4743</th>\n",
       "      <td>170517.jpg</td>\n",
       "      <td>long sleeve top</td>\n",
       "      <td>159</td>\n",
       "      <td>271</td>\n",
       "      <td>466</td>\n",
       "      <td>623</td>\n",
       "      <td>468</td>\n",
       "      <td>624</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             img    category_name   x1   y1   x2   y2  i_w   i_h\n",
       "3040  092400.jpg  long sleeve top  221  357  525  691  750  1125\n",
       "3608  142068.jpg  long sleeve top    0   91  375  682  424   756\n",
       "513   128992.jpg  long sleeve top  319  177  624  506  750   588\n",
       "2595  121091.jpg  long sleeve top    7    0  510  502  640   640\n",
       "4743  170517.jpg  long sleeve top  159  271  466  623  468   624"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Making all remaining class images the same length\n",
    "train_test = train_short_sub.groupby('category_name').sample(n=3000, random_state=5)\n",
    "train_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test['path'] = train_test['img'].apply(lambda x: 'home/ec2-user/SageMaker/effdet_df2/train/' + x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img</th>\n",
       "      <th>category_name</th>\n",
       "      <th>x1</th>\n",
       "      <th>y1</th>\n",
       "      <th>x2</th>\n",
       "      <th>y2</th>\n",
       "      <th>i_w</th>\n",
       "      <th>i_h</th>\n",
       "      <th>path</th>\n",
       "      <th>x3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3040</th>\n",
       "      <td>092400.jpg</td>\n",
       "      <td>long sleeve top</td>\n",
       "      <td>221</td>\n",
       "      <td>357</td>\n",
       "      <td>525</td>\n",
       "      <td>691</td>\n",
       "      <td>750</td>\n",
       "      <td>1125</td>\n",
       "      <td>home/ec2-user/SageMaker/effdet_df2/train/09240...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3608</th>\n",
       "      <td>142068.jpg</td>\n",
       "      <td>long sleeve top</td>\n",
       "      <td>0</td>\n",
       "      <td>91</td>\n",
       "      <td>375</td>\n",
       "      <td>682</td>\n",
       "      <td>424</td>\n",
       "      <td>756</td>\n",
       "      <td>home/ec2-user/SageMaker/effdet_df2/train/14206...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>513</th>\n",
       "      <td>128992.jpg</td>\n",
       "      <td>long sleeve top</td>\n",
       "      <td>319</td>\n",
       "      <td>177</td>\n",
       "      <td>624</td>\n",
       "      <td>506</td>\n",
       "      <td>750</td>\n",
       "      <td>588</td>\n",
       "      <td>home/ec2-user/SageMaker/effdet_df2/train/12899...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2595</th>\n",
       "      <td>121091.jpg</td>\n",
       "      <td>long sleeve top</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>510</td>\n",
       "      <td>502</td>\n",
       "      <td>640</td>\n",
       "      <td>640</td>\n",
       "      <td>home/ec2-user/SageMaker/effdet_df2/train/12109...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4743</th>\n",
       "      <td>170517.jpg</td>\n",
       "      <td>long sleeve top</td>\n",
       "      <td>159</td>\n",
       "      <td>271</td>\n",
       "      <td>466</td>\n",
       "      <td>623</td>\n",
       "      <td>468</td>\n",
       "      <td>624</td>\n",
       "      <td>home/ec2-user/SageMaker/effdet_df2/train/17051...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             img    category_name   x1   y1   x2   y2  i_w   i_h  \\\n",
       "3040  092400.jpg  long sleeve top  221  357  525  691  750  1125   \n",
       "3608  142068.jpg  long sleeve top    0   91  375  682  424   756   \n",
       "513   128992.jpg  long sleeve top  319  177  624  506  750   588   \n",
       "2595  121091.jpg  long sleeve top    7    0  510  502  640   640   \n",
       "4743  170517.jpg  long sleeve top  159  271  466  623  468   624   \n",
       "\n",
       "                                                   path x3  \n",
       "3040  home/ec2-user/SageMaker/effdet_df2/train/09240...     \n",
       "3608  home/ec2-user/SageMaker/effdet_df2/train/14206...     \n",
       "513   home/ec2-user/SageMaker/effdet_df2/train/12899...     \n",
       "2595  home/ec2-user/SageMaker/effdet_df2/train/12109...     \n",
       "4743  home/ec2-user/SageMaker/effdet_df2/train/17051...     "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_test[\"x3\"] = \"\"\n",
    "train_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test[\"y3\"] = \"\"\n",
    "train_test[\"x4\"] = \"\"\n",
    "train_test[\"y4\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_lab = train_test.loc[:, ['path', \"x1\", 'y1', 'x2', 'y2', 'category_name']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>x1</th>\n",
       "      <th>y1</th>\n",
       "      <th>x2</th>\n",
       "      <th>y2</th>\n",
       "      <th>category_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3040</th>\n",
       "      <td>home/ec2-user/SageMaker/effdet_df2/train/09240...</td>\n",
       "      <td>221</td>\n",
       "      <td>357</td>\n",
       "      <td>525</td>\n",
       "      <td>691</td>\n",
       "      <td>long sleeve top</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3608</th>\n",
       "      <td>home/ec2-user/SageMaker/effdet_df2/train/14206...</td>\n",
       "      <td>0</td>\n",
       "      <td>91</td>\n",
       "      <td>375</td>\n",
       "      <td>682</td>\n",
       "      <td>long sleeve top</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>513</th>\n",
       "      <td>home/ec2-user/SageMaker/effdet_df2/train/12899...</td>\n",
       "      <td>319</td>\n",
       "      <td>177</td>\n",
       "      <td>624</td>\n",
       "      <td>506</td>\n",
       "      <td>long sleeve top</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2595</th>\n",
       "      <td>home/ec2-user/SageMaker/effdet_df2/train/12109...</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>510</td>\n",
       "      <td>502</td>\n",
       "      <td>long sleeve top</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4743</th>\n",
       "      <td>home/ec2-user/SageMaker/effdet_df2/train/17051...</td>\n",
       "      <td>159</td>\n",
       "      <td>271</td>\n",
       "      <td>466</td>\n",
       "      <td>623</td>\n",
       "      <td>long sleeve top</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   path   x1   y1   x2   y2  \\\n",
       "3040  home/ec2-user/SageMaker/effdet_df2/train/09240...  221  357  525  691   \n",
       "3608  home/ec2-user/SageMaker/effdet_df2/train/14206...    0   91  375  682   \n",
       "513   home/ec2-user/SageMaker/effdet_df2/train/12899...  319  177  624  506   \n",
       "2595  home/ec2-user/SageMaker/effdet_df2/train/12109...    7    0  510  502   \n",
       "4743  home/ec2-user/SageMaker/effdet_df2/train/17051...  159  271  466  623   \n",
       "\n",
       "        category_name  \n",
       "3040  long sleeve top  \n",
       "3608  long sleeve top  \n",
       "513   long sleeve top  \n",
       "2595  long sleeve top  \n",
       "4743  long sleeve top  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_test_lab.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_lab.to_csv(\"/home/ec2-user/SageMaker/effdet_train.csv\", index=False, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# orig_file = 'DeepFashion2/validation/validation.json'\n",
    "# dest_file = '/home/ec2-user/SageMaker/validation.json'\n",
    "\n",
    "# # Connect to S3 bucket and download file - train.json\n",
    "# s3 = boto3.resource('s3')\n",
    "# s3.Bucket(bucket).download_file(orig_file, dest_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading in json\n",
    "val_df = pd.read_json(\"validation.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img</th>\n",
       "      <th>category_name</th>\n",
       "      <th>bounding_box</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000001.jpg</td>\n",
       "      <td>vest</td>\n",
       "      <td>[199, 190, 287, 269]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000002.jpg</td>\n",
       "      <td>vest</td>\n",
       "      <td>[170, 121, 280, 215]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000003.jpg</td>\n",
       "      <td>short sleeve dress</td>\n",
       "      <td>[151, 241, 279, 435]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000004.jpg</td>\n",
       "      <td>short sleeve dress</td>\n",
       "      <td>[174, 205, 327, 393]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000005.jpg</td>\n",
       "      <td>short sleeve top</td>\n",
       "      <td>[48, 0, 467, 623]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          img       category_name          bounding_box\n",
       "0  000001.jpg                vest  [199, 190, 287, 269]\n",
       "1  000002.jpg                vest  [170, 121, 280, 215]\n",
       "2  000003.jpg  short sleeve dress  [151, 241, 279, 435]\n",
       "3  000004.jpg  short sleeve dress  [174, 205, 327, 393]\n",
       "4  000005.jpg    short sleeve top     [48, 0, 467, 623]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_sub = val_df.loc[:, train_columns]\n",
    "val_sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "category_name\n",
       "long sleeve top       4414\n",
       "short sleeve dress    3026\n",
       "short sleeve top      9603\n",
       "trousers              2792\n",
       "Name: img, dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_short = val_sub[val_sub.category_name.isin(short_list)]\n",
    "val_short.groupby('category_name').count()['img']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img</th>\n",
       "      <th>bounding_box</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>category_name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>long sleeve top</th>\n",
       "      <td>2000</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>short sleeve dress</th>\n",
       "      <td>2000</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>short sleeve top</th>\n",
       "      <td>2000</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trousers</th>\n",
       "      <td>2000</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     img  bounding_box\n",
       "category_name                         \n",
       "long sleeve top     2000          2000\n",
       "short sleeve dress  2000          2000\n",
       "short sleeve top    2000          2000\n",
       "trousers            2000          2000"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_short_sub = val_short.groupby('category_name').sample(n=2000, random_state=5)\n",
    "val_short_sub.groupby('category_name').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['001465.jpg', '005883.jpg', '030278.jpg', '010727.jpg', '028952.jpg']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_list = list(val_short_sub['img'])\n",
    "val_list[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# s3 = boto3.resource('s3')\n",
    "\n",
    "# for image in val_list:\n",
    "#     orig_img = 'DeepFashion2/validation/image/' + image\n",
    "#     dest_img = '/home/ec2-user/SageMaker/effdet_df2/val/' + image\n",
    "    \n",
    "#     # Connect to S3 bucket and download image\n",
    "#     s3.Bucket(bucket).download_file(orig_img, dest_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000\n"
     ]
    }
   ],
   "source": [
    "temp_list = os.listdir('./effdet_df2/val')\n",
    "print(len(temp_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img</th>\n",
       "      <th>category_name</th>\n",
       "      <th>x1</th>\n",
       "      <th>y1</th>\n",
       "      <th>x2</th>\n",
       "      <th>y2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1464</th>\n",
       "      <td>001465.jpg</td>\n",
       "      <td>long sleeve top</td>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "      <td>466</td>\n",
       "      <td>623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5882</th>\n",
       "      <td>005883.jpg</td>\n",
       "      <td>long sleeve top</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>433</td>\n",
       "      <td>614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30277</th>\n",
       "      <td>030278.jpg</td>\n",
       "      <td>long sleeve top</td>\n",
       "      <td>327</td>\n",
       "      <td>129</td>\n",
       "      <td>548</td>\n",
       "      <td>448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10726</th>\n",
       "      <td>010727.jpg</td>\n",
       "      <td>long sleeve top</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>467</td>\n",
       "      <td>369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28951</th>\n",
       "      <td>028952.jpg</td>\n",
       "      <td>long sleeve top</td>\n",
       "      <td>208</td>\n",
       "      <td>121</td>\n",
       "      <td>444</td>\n",
       "      <td>431</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              img    category_name   x1   y1   x2   y2\n",
       "1464   001465.jpg  long sleeve top    1   45  466  623\n",
       "5882   005883.jpg  long sleeve top    0    0  433  614\n",
       "30277  030278.jpg  long sleeve top  327  129  548  448\n",
       "10726  010727.jpg  long sleeve top    0   36  467  369\n",
       "28951  028952.jpg  long sleeve top  208  121  444  431"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Making columns for the bounding box coordinates\n",
    "val_short_sub[['x1', 'y1', 'x2', 'y2']] = pd.DataFrame(\n",
    "    val_short_sub.bounding_box.tolist(), index=val_short_sub.index)\n",
    "val_short_sub.drop(columns=[\"bounding_box\"], inplace=True)\n",
    "val_short_sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dim = []\n",
    "for file in list(val_short_sub['img']):\n",
    "    i = Image.open('./effdet_df2/val/'+file)\n",
    "    val_dim.append([*i.size])\n",
    "val_dim_df = pd.DataFrame(val_dim, columns=['i_w', 'i_h'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      i_h\n",
      "i_w      \n",
      "468  3190\n",
      "      i_w\n",
      "i_h      \n",
      "624  1108\n"
     ]
    }
   ],
   "source": [
    "val_w = val_dim_df.groupby('i_w').count().sort_values(by='i_h', ascending=False).iloc[:1]\n",
    "val_h = val_dim_df.groupby('i_h').count().sort_values(by='i_w', ascending=False).iloc[:1]\n",
    "print(val_w)\n",
    "print(val_h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_short_sub = pd.concat([val_short_sub.reset_index(drop=True), val_dim_df.reset_index(drop=True)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "117\n"
     ]
    }
   ],
   "source": [
    "toosmall_val = val_short_sub[(val_short_sub['i_w'] < IMG_DIM) | (val_short_sub['i_h'] < IMG_DIM)]\n",
    "print(len(toosmall_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img</th>\n",
       "      <th>category_name</th>\n",
       "      <th>x1</th>\n",
       "      <th>y1</th>\n",
       "      <th>x2</th>\n",
       "      <th>y2</th>\n",
       "      <th>i_w</th>\n",
       "      <th>i_h</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>001465.jpg</td>\n",
       "      <td>long sleeve top</td>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "      <td>466</td>\n",
       "      <td>623</td>\n",
       "      <td>468</td>\n",
       "      <td>624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>005883.jpg</td>\n",
       "      <td>long sleeve top</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>433</td>\n",
       "      <td>614</td>\n",
       "      <td>468</td>\n",
       "      <td>624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>030278.jpg</td>\n",
       "      <td>long sleeve top</td>\n",
       "      <td>327</td>\n",
       "      <td>129</td>\n",
       "      <td>548</td>\n",
       "      <td>448</td>\n",
       "      <td>880</td>\n",
       "      <td>587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>010727.jpg</td>\n",
       "      <td>long sleeve top</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>467</td>\n",
       "      <td>369</td>\n",
       "      <td>468</td>\n",
       "      <td>624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>028952.jpg</td>\n",
       "      <td>long sleeve top</td>\n",
       "      <td>208</td>\n",
       "      <td>121</td>\n",
       "      <td>444</td>\n",
       "      <td>431</td>\n",
       "      <td>640</td>\n",
       "      <td>432</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          img    category_name   x1   y1   x2   y2  i_w  i_h\n",
       "0  001465.jpg  long sleeve top    1   45  466  623  468  624\n",
       "1  005883.jpg  long sleeve top    0    0  433  614  468  624\n",
       "2  030278.jpg  long sleeve top  327  129  548  448  880  587\n",
       "3  010727.jpg  long sleeve top    0   36  467  369  468  624\n",
       "4  028952.jpg  long sleeve top  208  121  444  431  640  432"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_short_sub = val_short_sub[~val_short_sub.img.isin(toosmall_val.img)]\n",
    "val_short_sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "category_name\n",
       "long sleeve top       1974\n",
       "short sleeve dress    1957\n",
       "short sleeve top      1975\n",
       "trousers              1977\n",
       "Name: img, dtype: int64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_short_sub.groupby('category_name').count()['img']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img</th>\n",
       "      <th>category_name</th>\n",
       "      <th>x1</th>\n",
       "      <th>y1</th>\n",
       "      <th>x2</th>\n",
       "      <th>y2</th>\n",
       "      <th>i_w</th>\n",
       "      <th>i_h</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1697</th>\n",
       "      <td>027129.jpg</td>\n",
       "      <td>long sleeve top</td>\n",
       "      <td>305</td>\n",
       "      <td>232</td>\n",
       "      <td>654</td>\n",
       "      <td>556</td>\n",
       "      <td>880</td>\n",
       "      <td>557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>938</th>\n",
       "      <td>020098.jpg</td>\n",
       "      <td>long sleeve top</td>\n",
       "      <td>133</td>\n",
       "      <td>2</td>\n",
       "      <td>464</td>\n",
       "      <td>455</td>\n",
       "      <td>640</td>\n",
       "      <td>497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>422</th>\n",
       "      <td>022818.jpg</td>\n",
       "      <td>long sleeve top</td>\n",
       "      <td>135</td>\n",
       "      <td>259</td>\n",
       "      <td>542</td>\n",
       "      <td>898</td>\n",
       "      <td>750</td>\n",
       "      <td>951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>834</th>\n",
       "      <td>009767.jpg</td>\n",
       "      <td>long sleeve top</td>\n",
       "      <td>1</td>\n",
       "      <td>137</td>\n",
       "      <td>466</td>\n",
       "      <td>623</td>\n",
       "      <td>468</td>\n",
       "      <td>624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1357</th>\n",
       "      <td>002970.jpg</td>\n",
       "      <td>long sleeve top</td>\n",
       "      <td>21</td>\n",
       "      <td>9</td>\n",
       "      <td>467</td>\n",
       "      <td>443</td>\n",
       "      <td>468</td>\n",
       "      <td>624</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             img    category_name   x1   y1   x2   y2  i_w  i_h\n",
       "1697  027129.jpg  long sleeve top  305  232  654  556  880  557\n",
       "938   020098.jpg  long sleeve top  133    2  464  455  640  497\n",
       "422   022818.jpg  long sleeve top  135  259  542  898  750  951\n",
       "834   009767.jpg  long sleeve top    1  137  466  623  468  624\n",
       "1357  002970.jpg  long sleeve top   21    9  467  443  468  624"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_test = val_short_sub.groupby('category_name').sample(n=500, random_state=5)\n",
    "val_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_test['path'] = val_test['img'].apply(lambda x: 'home/ec2-user/SageMaker/effdet_df2/val/' + x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_test[\"x3\"] = \"\"\n",
    "val_test[\"y3\"] = \"\"\n",
    "val_test[\"x4\"] = \"\"\n",
    "val_test[\"y4\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_test_lab = val_test.loc[:, ['path', 'x1', 'y1', 'x2', 'y2', 'category_name']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_test_lab.to_csv(\"/home/ec2-user/SageMaker/effdet_val.csv\", index=False, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making Class map file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_list = ['short sleeve top', 'trousers', 'long sleeve top', 'short sleeve dress']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_num = list(range(0, len(class_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>short sleeve top</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>trousers</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>long sleeve top</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>short sleeve dress</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    0  1\n",
       "0    short sleeve top  0\n",
       "1            trousers  1\n",
       "2     long sleeve top  2\n",
       "3  short sleeve dress  3"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_df = pd.DataFrame(list(zip(class_list, class_num)))\n",
    "class_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_df.to_csv(\"/home/ec2-user/SageMaker/classes.csv\", index=False, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing the EfficientDet model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-29T04:10:01.423519Z",
     "start_time": "2021-09-29T04:10:01.280535Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'EfficientDet'...\n",
      "remote: Enumerating objects: 394, done.\u001b[K\n",
      "remote: Total 394 (delta 0), reused 0 (delta 0), pack-reused 394\u001b[K\n",
      "Receiving objects: 100% (394/394), 1.50 MiB | 10.63 MiB/s, done.\n",
      "Resolving deltas: 100% (242/242), done.\n"
     ]
    }
   ],
   "source": [
    "# Downloading the github project for EfficientDet\n",
    "!git clone https://github.com/xuannianz/EfficientDet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('./EfficientDet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/ec2-user/SageMaker/EfficientDet'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting keras_applications\n",
      "  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n",
      "\u001b[K     |████████████████████████████████| 50 kB 4.5 MB/s eta 0:00:011\n",
      "\u001b[?25hRequirement already satisfied: h5py in /home/ec2-user/anaconda3/envs/amazonei_tensorflow2_p36/lib/python3.6/site-packages (from keras_applications) (2.10.0)\n",
      "Requirement already satisfied: numpy>=1.9.1 in /home/ec2-user/anaconda3/envs/amazonei_tensorflow2_p36/lib/python3.6/site-packages (from keras_applications) (1.18.5)\n",
      "Requirement already satisfied: six in /home/ec2-user/anaconda3/envs/amazonei_tensorflow2_p36/lib/python3.6/site-packages (from h5py->keras_applications) (1.15.0)\n",
      "Installing collected packages: keras-applications\n",
      "Successfully installed keras-applications-1.0.8\n"
     ]
    }
   ],
   "source": [
    "!pip3 install keras_applications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date\n",
    "import os\n",
    "import sys\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "\n",
    "from augmentor.color import VisualEffect\n",
    "from augmentor.misc import MiscEffect\n",
    "from model import efficientdet\n",
    "from losses import smooth_l1, focal, smooth_l1_quad\n",
    "from efficientnet import BASE_WEIGHTS_PATH, WEIGHTS_HASHES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 15754309519806406067\n",
      ", name: \"/device:XLA_CPU:0\"\n",
      "device_type: \"XLA_CPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 6593612218255737979\n",
      "physical_device_desc: \"device: XLA_CPU device\"\n",
      ", name: \"/device:XLA_GPU:0\"\n",
      "device_type: \"XLA_GPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 215700319328743365\n",
      "physical_device_desc: \"device: XLA_GPU device\"\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 14648653952\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 12355927375365208742\n",
      "physical_device_desc: \"device: 0, name: Tesla T4, pci bus id: 0000:00:1e.0, compute capability: 7.5\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "phi = 3    # Model size\n",
    "detect_text = False\n",
    "snapshot = \"imagenet\"\n",
    "gpu = \"0\"\n",
    "\n",
    "dataset_type = 'csv'\n",
    "train_path = \"/home/ec2-user/SageMaker/effdet_train.csv\"\n",
    "class_path = \"classes.csv\"\n",
    "val_path = \"/home/ec2-user/SageMaker/effdet_val.csv\"\n",
    "\n",
    "freeze_backbone = True\n",
    "compute_val_loss = True\n",
    "weighted_bifpn = False\n",
    "freeze_bn = False\n",
    "tensorboard_dir = 'logs/{}'.format(str(date.today()))\n",
    "evaluation = True\n",
    "snapshots_store = True\n",
    "\n",
    "epochs = 10\n",
    "NUM_TRAIN = 12000\n",
    "NUM_TEST = 2000\n",
    "\n",
    "steps = NUM_TRAIN //batch_size,\n",
    "val_steps= NUM_TEST //batch_size\n",
    "\n",
    "workers = 4\n",
    "dropout_rate = 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This is from the train.py in the cloned repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_generators(dataset_type, train_path, class_path, batch_size, phi, detect_text,\n",
    "                      val_path=None, random_transform=None):\n",
    "    \"\"\"\n",
    "    Create generators for training and validation.\n",
    "\n",
    "        preprocess_image: Function that preprocesses an image for the network.\n",
    "    \"\"\"\n",
    "    common_args = {\n",
    "        'batch_size': batch_size,\n",
    "        'phi': phi,\n",
    "        'detect_text': detect_text,\n",
    "        'detect_quadrangle': False\n",
    "    }\n",
    "\n",
    "    # create random transform generator for augmenting training data\n",
    "    if random_transform:\n",
    "        misc_effect = MiscEffect()\n",
    "        visual_effect = VisualEffect()\n",
    "    else:\n",
    "        misc_effect = None\n",
    "        visual_effect = None\n",
    "\n",
    "    if dataset_type == 'csv':\n",
    "        from generators.csv_ import CSVGenerator\n",
    "        train_generator = CSVGenerator(\n",
    "            train_path,\n",
    "            class_path,\n",
    "            misc_effect=misc_effect,\n",
    "            visual_effect=visual_effect,\n",
    "            **common_args\n",
    "        )\n",
    "        if val_path:\n",
    "            validation_generator = CSVGenerator(\n",
    "                val_path,\n",
    "                class_path,\n",
    "                shuffle_groups=False,\n",
    "                **common_args\n",
    "            )\n",
    "        else:\n",
    "            validation_generator = None\n",
    "\n",
    "    else:\n",
    "        raise ValueError('Invalid data type received: {}'.format(dataset_type))\n",
    "\n",
    "    return train_generator, validation_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_callbacks(training_model, prediction_model, validation_generator, tensorboard_dir, batch_size,\n",
    "                    evaluation, snapshots):\n",
    "    \"\"\"\n",
    "    Creates the callbacks to use during training.\n",
    "    Args\n",
    "        training_model: The model that is used for training.\n",
    "        prediction_model: The model that should be used for validation.\n",
    "        validation_generator: The generator for creating validation data.\n",
    "        args: parseargs args object.\n",
    "    Returns:\n",
    "        A list of callbacks used for training.\n",
    "    \"\"\"\n",
    "    callbacks = []\n",
    "\n",
    "    tensorboard_callback = None\n",
    "\n",
    "    if tensorboard_dir:\n",
    "        if tf.version.VERSION > '2.0.0':\n",
    "            file_writer = tf.summary.create_file_writer(tensorboard_dir)\n",
    "            file_writer.set_as_default()\n",
    "        tensorboard_callback = keras.callbacks.TensorBoard(\n",
    "            log_dir=tensorboard_dir,\n",
    "            histogram_freq=0,\n",
    "            batch_size=batch_size,\n",
    "            write_graph=True,\n",
    "            write_grads=False,\n",
    "            write_images=False,\n",
    "            embeddings_freq=0,\n",
    "            embeddings_layer_names=None,\n",
    "            embeddings_metadata=None\n",
    "        )\n",
    "        callbacks.append(tensorboard_callback)\n",
    "\n",
    "    if evaluation and validation_generator:\n",
    "        if dataset_type == 'coco':\n",
    "            from eval.coco import Evaluate\n",
    "            # use prediction model for evaluation\n",
    "            evaluation = Evaluate(validation_generator, prediction_model, tensorboard=tensorboard_callback)\n",
    "        else:\n",
    "            from eval.pascal import Evaluate\n",
    "            evaluation = Evaluate(validation_generator, prediction_model, tensorboard=tensorboard_callback)\n",
    "        callbacks.append(evaluation)\n",
    "\n",
    "    # save the model\n",
    "    if snapshots:\n",
    "        # ensure directory created first; otherwise h5py will error after epoch.\n",
    "        makedirs(snapshot_path)\n",
    "        checkpoint = keras.callbacks.ModelCheckpoint(\n",
    "            os.path.join(\n",
    "                snapshot_path,\n",
    "                f'{dataset_type}_{{epoch:02d}}_{{loss:.4f}}_{{val_loss:.4f}}.h5' if compute_val_loss\n",
    "                else f'{dataset_type}_{{epoch:02d}}_{{loss:.4f}}.h5'\n",
    "            ),\n",
    "            verbose=1,\n",
    "            save_weights_only=True,\n",
    "            monitor=\"mAP\",\n",
    "            # mode='max'\n",
    "        )\n",
    "        callbacks.append(checkpoint)\n",
    "\n",
    "    # callbacks.append(keras.callbacks.ReduceLROnPlateau(\n",
    "    #     monitor='loss',\n",
    "    #     factor=0.1,\n",
    "    #     patience=2,\n",
    "    #     verbose=1,\n",
    "    #     mode='auto',\n",
    "    #     min_delta=0.0001,\n",
    "    #     cooldown=0,\n",
    "    #     min_lr=0\n",
    "    # ))\n",
    "\n",
    "    return callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "It appears you are trying to construct a functional model, but not all of the inputs in the first positional argument of your layer call are symbolic tensors. (Input objects, or the output of another layer) Functional models cannot correctly track custom layers unless all values in the first call argument are symbolic.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-72-dda2a0638032>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m                                        \u001b[0mweighted_bifpn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mweighted_bifpn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                                        \u001b[0mfreeze_bn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfreeze_bn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m                                        \u001b[0mdetect_quadrangle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m                                        )\n\u001b[1;32m     20\u001b[0m \u001b[0;31m# load pretrained weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/SageMaker/EfficientDet/model.py\u001b[0m in \u001b[0;36mefficientdet\u001b[0;34m(phi, num_classes, num_anchors, weighted_bifpn, freeze_bn, score_threshold, detect_quadrangle, anchor_parameters, separable_conv)\u001b[0m\n\u001b[1;32m    441\u001b[0m     class_net = ClassNet(w_head, d_head, num_classes=num_classes, num_anchors=num_anchors,\n\u001b[1;32m    442\u001b[0m                          separable_conv=separable_conv, freeze_bn=freeze_bn, name='class_net')\n\u001b[0;32m--> 443\u001b[0;31m     \u001b[0mclassification\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mclass_net\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfpn_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    444\u001b[0m     \u001b[0mclassification\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'classification'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassification\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m     \u001b[0mregression\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbox_net\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfpn_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/SageMaker/EfficientDet/model.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    441\u001b[0m     class_net = ClassNet(w_head, d_head, num_classes=num_classes, num_anchors=num_anchors,\n\u001b[1;32m    442\u001b[0m                          separable_conv=separable_conv, freeze_bn=freeze_bn, name='class_net')\n\u001b[0;32m--> 443\u001b[0;31m     \u001b[0mclassification\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mclass_net\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfpn_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    444\u001b[0m     \u001b[0mclassification\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'classification'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassification\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m     \u001b[0mregression\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbox_net\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfpn_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/amazonei_tensorflow2_p36/lib/python3.6/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    922\u001b[0m     \u001b[0;31m# >> outputs = MyLayer()(inputs)  # Functional construction mode.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    923\u001b[0m     \u001b[0;31m# >> model = tf.keras.Model(inputs, outputs)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 924\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0m_in_functional_construction_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    925\u001b[0m       return self._functional_construction_call(inputs, args, kwargs,\n\u001b[1;32m    926\u001b[0m                                                 input_list)\n",
      "\u001b[0;32m~/anaconda3/envs/amazonei_tensorflow2_p36/lib/python3.6/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_in_functional_construction_mode\u001b[0;34m(layer, inputs, args, kwargs, input_list)\u001b[0m\n\u001b[1;32m   3221\u001b[0m           any(tf_utils.is_symbolic_tensor(t) for t in nest.flatten(\n\u001b[1;32m   3222\u001b[0m               [inputs, args, kwargs])) and not all_inputs_symbolic):\n\u001b[0;32m-> 3223\u001b[0;31m         raise ValueError('It appears you are trying to construct a '\n\u001b[0m\u001b[1;32m   3224\u001b[0m                          \u001b[0;34m'functional model, but not all of the inputs in '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3225\u001b[0m                          \u001b[0;34m'the first positional argument of your layer call '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: It appears you are trying to construct a functional model, but not all of the inputs in the first positional argument of your layer call are symbolic tensors. (Input objects, or the output of another layer) Functional models cannot correctly track custom layers unless all values in the first call argument are symbolic."
     ]
    }
   ],
   "source": [
    "# create the generators\n",
    "train_generator, validation_generator = create_generators(dataset_type, train_path, class_path,\n",
    "                                                          batch_size, phi, detect_text, val_path)\n",
    "\n",
    "num_classes = train_generator.num_classes()\n",
    "num_anchors = train_generator.num_anchors\n",
    "\n",
    "# optionally choose specific GPU\n",
    "if gpu:\n",
    "    os.environ['CUDA_VISIBLE_DEVICES'] = gpu\n",
    "\n",
    "\n",
    "model, prediction_model = efficientdet(phi,\n",
    "                                       num_classes=num_classes,\n",
    "                                       num_anchors=num_anchors,\n",
    "                                       weighted_bifpn=weighted_bifpn,\n",
    "                                       freeze_bn=freeze_bn,\n",
    "                                       detect_quadrangle=False\n",
    "                                       )\n",
    "# load pretrained weights\n",
    "if snapshot:\n",
    "    if snapshot == 'imagenet':\n",
    "        model_name = 'efficientnet-b{}'.format(phi)\n",
    "        file_name = '{}_weights_tf_dim_ordering_tf_kernels_autoaugment_notop.h5'.format(model_name)\n",
    "        file_hash = WEIGHTS_HASHES[model_name][1]\n",
    "        weights_path = keras.utils.get_file(file_name,\n",
    "                                            BASE_WEIGHTS_PATH + file_name,\n",
    "                                            cache_subdir='models',\n",
    "                                            file_hash=file_hash)\n",
    "        model.load_weights(weights_path, by_name=True)\n",
    "    else:\n",
    "        print('Loading model, this may take a second...')\n",
    "        model.load_weights(snapshot, by_name=True)\n",
    "\n",
    "# freeze backbone layers\n",
    "if freeze_backbone:\n",
    "    # 227, 329, 329, 374, 464, 566, 656\n",
    "    for i in range(1, [227, 329, 329, 374, 464, 566, 656][phi]):\n",
    "        model.layers[i].trainable = False\n",
    "\n",
    "if gpu and len(gpu.split(',')) > 1:\n",
    "    model = keras.utils.multi_gpu_model(model, gpus=list(map(int, gpu.split(','))))\n",
    "\n",
    "# compile model\n",
    "model.compile(optimizer=Adam(lr=1e-3), loss={\n",
    "    'regression': smooth_l1_quad() if detect_quadrangle else smooth_l1(),\n",
    "    'classification': focal()\n",
    "}, )\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "# create the callbacks\n",
    "callbacks = create_callbacks(\n",
    "    model,\n",
    "    prediction_model,\n",
    "    validation_generator,\n",
    "    tensorboard_dir,\n",
    "    batch_size,\n",
    "    evaluation,\n",
    "    snapshots_store\n",
    ")\n",
    "\n",
    "if not compute_val_loss:\n",
    "    validation_generator = None\n",
    "elif compute_val_loss and validation_generator is None:\n",
    "    raise ValueError('When you have no validation data, you should not specify --compute-val-loss.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start training\n",
    "model.fit_generator(\n",
    "    generator=train_generator,\n",
    "    steps_per_epoch=steps,\n",
    "    epochs=epochs,\n",
    "    verbose=1,\n",
    "    callbacks=callbacks,\n",
    "    workers=workers,\n",
    "    use_multiprocessing=True,\n",
    "    validation_data=validation_generator\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs_x = range(len(acc))\n",
    "\n",
    "plt.plot(epochs_x, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs_x, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs_x, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs_x, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: df2_model_effnet/assets\n"
     ]
    }
   ],
   "source": [
    "model.save(\"df2_model_effnet\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_amazonei_tensorflow2_p36",
   "language": "python",
   "name": "conda_amazonei_tensorflow2_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
