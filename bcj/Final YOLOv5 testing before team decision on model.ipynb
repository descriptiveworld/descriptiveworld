{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "nutritional-avenue",
   "metadata": {},
   "source": [
    "# Overview\n",
    "\n",
    "\n",
    "This notebook contains test runs of various model and dataset scenarios.\n",
    "\n",
    "### NOTES:\n",
    "\n",
    "- A change to yolov5/val.py was required to run this on OSX:\n",
    "    change call to create_dataloader(), to include workers=0\n",
    "    \n",
    "    per:  https://stackoverflow.com/questions/64772335/pytorch-w-parallelnative-cpp206![image.png](attachment:image.png)\n",
    "    \n",
    "  \n",
    "- DF1 dataset was extracted into a single 4-class set\n",
    "\n",
    "    For DF1, some images were found to have  poorly defined bounding boxes / excessive blank-space.  An algorithm was applied to attempt to filter out these images from the training, validation and test sets.\n",
    "    \n",
    "\n",
    "- DF2 dataset was extracted into two sets:\n",
    "\n",
    "    - 4 classes\n",
    "    \n",
    "    - 11 classes\n",
    "    \n",
    "    \n",
    "    In both DF2 cases, some samples were filtered out.  The criteria to include samples were:\n",
    "        - source==â€˜shopâ€™\n",
    "        - scale>1\n",
    "        - occlusion<2\n",
    "        - zoom<2\n",
    "        - viewpoint<3\n",
    "\n",
    "All images used were resized to maximum 640x640.\n",
    "\n",
    "Although Test data was extracted from the Train dataset for DF1 and DF2, the Test is guaranteed to be unseen samples (none were included in the data used for training).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ranging-drove",
   "metadata": {},
   "source": [
    "# <span style='color:blue'>Scenario:  4-class models</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "miniature-combine",
   "metadata": {},
   "source": [
    "## <span style='color:darkgreen'>DF1-Test data</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beautiful-perception",
   "metadata": {},
   "source": [
    "### Model Test 4.A\n",
    "\n",
    "- Model: DF1-trained 4-class model\n",
    "- Dataset:  DF1-Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "criminal-attraction",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mdata=/Users/blairjones/Desktop/w210/yolov5/data/df1_test.yaml, weights=['./DeepFashion1/bcj_experiments/exp_DF1_DF2_align/exp2/weights/best.pt'], batch_size=16, imgsz=640, conf_thres=0.001, iou_thres=0.6, task=test, device=, single_cls=False, augment=False, verbose=False, save_txt=False, save_hybrid=False, save_conf=False, save_json=False, project=yolov5/runs/val, name=exp, exist_ok=False, half=False\n",
      "YOLOv5 ðŸš€ v6.0-6-gd0bfeb3 torch 1.9.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model Summary: 213 layers, 7020913 parameters, 0 gradients\n",
      "\u001b[34m\u001b[1mtest: \u001b[0mScanning 'DeepFashion1/fashion/labels/test/1981_Graphic_Ringer_Tee.cache' \u001b[0m\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       1707       1707       0.76      0.792       0.84      0.655\n",
      "     long sleeve top       1707        420      0.751      0.698       0.78      0.572\n",
      "    short sleeve top       1707        418      0.784      0.737      0.835      0.652\n",
      "              shorts       1707        430      0.768      0.833      0.866      0.683\n",
      "            trousers       1707        439      0.736      0.902      0.878      0.713\n",
      "Speed: 0.5ms pre-process, 241.2ms inference, 0.5ms NMS per image at shape (16, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov5/runs/val/exp27\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python yolov5/val.py --batch-size 16 --data fashion_test.yaml --weights ./DeepFashion1/bcj_experiments/exp_DF1_DF2_align/exp2/weights/best.pt --img 640 --task test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "peripheral-vertical",
   "metadata": {},
   "source": [
    "### Model Test 4.B\n",
    "\n",
    "- Model: DF2-trained 4-class model\n",
    "- Dataset:  DF1-Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "returning-classic",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mdata=/Users/blairjones/Desktop/w210/yolov5/data/fashion_test.yaml, weights=['./DeepFashion2/bcj_experiments/exp3/weights/best.pt'], batch_size=16, imgsz=640, conf_thres=0.001, iou_thres=0.6, task=test, device=, single_cls=False, augment=False, verbose=False, save_txt=False, save_hybrid=False, save_conf=False, save_json=False, project=yolov5/runs/val, name=exp, exist_ok=False, half=False\n",
      "YOLOv5 ðŸš€ v6.0-6-gd0bfeb3 torch 1.9.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model Summary: 224 layers, 7062001 parameters, 0 gradients\n",
      "\u001b[34m\u001b[1mtest: \u001b[0mScanning 'DeepFashion1/fashion/labels/test/1981_Graphic_Ringer_Tee.cache' \u001b[0m\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       1707       1707       0.59      0.658      0.605      0.297\n",
      "     long sleeve top       1707        420      0.455      0.652      0.467       0.23\n",
      "    short sleeve top       1707        418      0.542      0.488      0.511      0.287\n",
      "              shorts       1707        430      0.683       0.66       0.67      0.278\n",
      "            trousers       1707        439      0.678      0.829      0.772      0.394\n",
      "Speed: 0.5ms pre-process, 258.4ms inference, 0.5ms NMS per image at shape (16, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov5/runs/val/exp\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python yolov5/val.py --batch-size 16 --data fashion_test.yaml --weights ./DeepFashion2/bcj_experiments/exp3/weights/best.pt --img 640 --task test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "elegant-signature",
   "metadata": {},
   "source": [
    "### Model Test 4.C\n",
    "\n",
    "- Model: Ensemble of DF1-trained and DF2-trained 4-class models\n",
    "- Dataset:  DF1-Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "perfect-reading",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mdata=/Users/blairjones/Desktop/w210/yolov5/data/fashion_test.yaml, weights=['./DeepFashion1/bcj_experiments/exp_DF1_DF2_align/exp2/weights/best.pt', './DeepFashion2/bcj_experiments/exp3/weights/best.pt'], batch_size=16, imgsz=640, conf_thres=0.001, iou_thres=0.6, task=test, device=, single_cls=False, augment=False, verbose=False, save_txt=False, save_hybrid=False, save_conf=False, save_json=False, project=yolov5/runs/val, name=exp, exist_ok=False, half=False\n",
      "YOLOv5 ðŸš€ v6.0-6-gd0bfeb3 torch 1.9.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model Summary: 213 layers, 7020913 parameters, 0 gradients\n",
      "Fusing layers... \n",
      "Model Summary: 224 layers, 7062001 parameters, 0 gradients\n",
      "Ensemble created with ['./DeepFashion1/bcj_experiments/exp_DF1_DF2_align/exp2/weights/best.pt', './DeepFashion2/bcj_experiments/exp3/weights/best.pt']\n",
      "\n",
      "\u001b[34m\u001b[1mtest: \u001b[0mScanning 'DeepFashion1/fashion/labels/test/1981_Graphic_Ringer_Tee.cache' \u001b[0m\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       1707       1707      0.683      0.765      0.745      0.454\n",
      "     long sleeve top       1707        420      0.586      0.697      0.596      0.339\n",
      "    short sleeve top       1707        418      0.707      0.708      0.743      0.506\n",
      "              shorts       1707        430      0.737      0.791      0.814      0.489\n",
      "            trousers       1707        439      0.704      0.866      0.826      0.483\n",
      "Speed: 0.5ms pre-process, 496.8ms inference, 0.7ms NMS per image at shape (16, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov5/runs/val/exp4\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python yolov5/val.py --batch-size 16 --data fashion_test.yaml --weights ./DeepFashion1/bcj_experiments/exp_DF1_DF2_align/exp2/weights/best.pt ./DeepFashion2/bcj_experiments/exp3/weights/best.pt --img 640 --task test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bulgarian-basketball",
   "metadata": {},
   "outputs": [],
   "source": [
    "#started-21:11, finished-21:25"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "authentic-wayne",
   "metadata": {},
   "source": [
    "## <span style='color:darkgreen'>DF2-Test data</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mounted-advisory",
   "metadata": {},
   "source": [
    "### Model Test 4.D\n",
    "\n",
    "- Model: DF1-trained 4-class model\n",
    "- Dataset:  DF2-Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "portuguese-castle",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mdata=/Users/blairjones/Desktop/w210/yolov5/data/fashion_all_test_3.yaml, weights=['./DeepFashion1/bcj_experiments/exp_DF1_DF2_align/exp2/weights/best.pt'], batch_size=16, imgsz=640, conf_thres=0.001, iou_thres=0.6, task=test, device=, single_cls=False, augment=False, verbose=False, save_txt=False, save_hybrid=False, save_conf=False, save_json=False, project=yolov5/runs/val, name=exp, exist_ok=False, half=False\n",
      "YOLOv5 ðŸš€ v6.0-6-gd0bfeb3 torch 1.9.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model Summary: 213 layers, 7020913 parameters, 0 gradients\n",
      "\u001b[34m\u001b[1mtest: \u001b[0mScanning 'DeepFashion2/df2_all/labels/test_3' images and labels...1598 fou\u001b[0m\n",
      "\u001b[34m\u001b[1mtest: \u001b[0mNew cache created: DeepFashion2/df2_all/labels/test_3.cache\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       1598       1598      0.607      0.817      0.759      0.383\n",
      "     long sleeve top       1598        400      0.591      0.695      0.672      0.361\n",
      "    short sleeve top       1598        398      0.532      0.754      0.666      0.414\n",
      "              shorts       1598        400      0.556       0.94      0.831       0.35\n",
      "            trousers       1598        400      0.749       0.88      0.868      0.408\n",
      "Speed: 0.4ms pre-process, 225.9ms inference, 0.5ms NMS per image at shape (16, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov5/runs/val/exp9\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python yolov5/val.py --batch-size 16 --data fashion_all_test_3.yaml --weights ./DeepFashion1/bcj_experiments/exp_DF1_DF2_align/exp2/weights/best.pt --img 640 --task test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "portable-priest",
   "metadata": {},
   "outputs": [],
   "source": [
    "#started-09:25, finished-09:30"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "political-meaning",
   "metadata": {},
   "source": [
    "### Model Test 4.E\n",
    "\n",
    "- Model: DF2-trained 4-class model\n",
    "- Dataset:  DF2-Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "graduate-slovakia",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mdata=/Users/blairjones/Desktop/w210/yolov5/data/fashion_all_test_3.yaml, weights=['./DeepFashion2/bcj_experiments/exp3/weights/best.pt'], batch_size=16, imgsz=640, conf_thres=0.001, iou_thres=0.6, task=test, device=, single_cls=False, augment=False, verbose=False, save_txt=False, save_hybrid=False, save_conf=False, save_json=False, project=yolov5/runs/val, name=exp, exist_ok=False, half=False\n",
      "YOLOv5 ðŸš€ v6.0-6-gd0bfeb3 torch 1.9.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model Summary: 224 layers, 7062001 parameters, 0 gradients\n",
      "\u001b[34m\u001b[1mtest: \u001b[0mScanning 'DeepFashion2/df2_all/labels/test_3.cache' images and labels... 1\u001b[0m\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       1598       1598      0.805      0.919      0.915      0.742\n",
      "     long sleeve top       1598        400      0.809      0.905      0.897      0.668\n",
      "    short sleeve top       1598        398      0.757      0.852      0.868      0.683\n",
      "              shorts       1598        400      0.808       0.94      0.938      0.792\n",
      "            trousers       1598        400      0.846       0.98      0.957      0.823\n",
      "Speed: 0.4ms pre-process, 235.1ms inference, 0.5ms NMS per image at shape (16, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov5/runs/val/exp10\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python yolov5/val.py --batch-size 16 --data fashion_all_test_3.yaml --weights ./DeepFashion2/bcj_experiments/exp3/weights/best.pt --img 640 --task test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "official-cambridge",
   "metadata": {},
   "outputs": [],
   "source": [
    "#started-09:30, finished-09:37"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "special-volume",
   "metadata": {},
   "source": [
    "### Model Test 4.F\n",
    "\n",
    "- Model: Ensemble of DF1-trained and DF2-trained 4-class models\n",
    "- Dataset:  DF2-Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "associate-covering",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mdata=/Users/blairjones/Desktop/w210/yolov5/data/fashion_all_test_3.yaml, weights=['./DeepFashion1/bcj_experiments/exp_DF1_DF2_align/exp2/weights/best.pt', './DeepFashion2/bcj_experiments/exp3/weights/best.pt'], batch_size=16, imgsz=640, conf_thres=0.001, iou_thres=0.6, task=test, device=, single_cls=False, augment=False, verbose=False, save_txt=False, save_hybrid=False, save_conf=False, save_json=False, project=yolov5/runs/val, name=exp, exist_ok=False, half=False\n",
      "YOLOv5 ðŸš€ v6.0-6-gd0bfeb3 torch 1.9.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model Summary: 213 layers, 7020913 parameters, 0 gradients\n",
      "Fusing layers... \n",
      "Model Summary: 224 layers, 7062001 parameters, 0 gradients\n",
      "Ensemble created with ['./DeepFashion1/bcj_experiments/exp_DF1_DF2_align/exp2/weights/best.pt', './DeepFashion2/bcj_experiments/exp3/weights/best.pt']\n",
      "\n",
      "\u001b[34m\u001b[1mtest: \u001b[0mScanning 'DeepFashion2/df2_all/labels/test_3.cache' images and labels... 1\u001b[0m\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       1598       1598      0.787      0.879        0.9      0.692\n",
      "     long sleeve top       1598        400      0.838      0.802      0.888      0.657\n",
      "    short sleeve top       1598        398      0.766      0.812      0.848      0.646\n",
      "              shorts       1598        400      0.723      0.934      0.917      0.686\n",
      "            trousers       1598        400       0.82      0.968      0.948      0.779\n",
      "Speed: 0.4ms pre-process, 452.2ms inference, 0.6ms NMS per image at shape (16, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov5/runs/val/exp11\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python yolov5/val.py --batch-size 16 --data fashion_all_test_3.yaml --weights ./DeepFashion1/bcj_experiments/exp_DF1_DF2_align/exp2/weights/best.pt ./DeepFashion2/bcj_experiments/exp3/weights/best.pt --img 640 --task test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "viral-dinner",
   "metadata": {},
   "outputs": [],
   "source": [
    "#started-09:44, finished-10:02"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "plastic-costs",
   "metadata": {},
   "source": [
    "# <span style='color:blue'>Scenario:  11-class models</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "editorial-context",
   "metadata": {},
   "source": [
    "### Model Test 11.A\n",
    "\n",
    "- Model: DF2-trained 11-class model\n",
    "- Dataset:  DF2-Test-1.  Composed of random sample from Train data, only 1,312 samples per class were used for training.  Despite the random sampling, this data could contain some samples that were in the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dominant-birth",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mdata=/Users/blairjones/Desktop/w210/yolov5/data/fashion_all_test.yaml, weights=['./DeepFashion2/bcj_experiments/df2_all/exp2/weights/best.pt'], batch_size=16, imgsz=640, conf_thres=0.001, iou_thres=0.6, task=test, device=, single_cls=False, augment=False, verbose=False, save_txt=False, save_hybrid=False, save_conf=False, save_json=False, project=yolov5/runs/val, name=exp, exist_ok=False, half=False\n",
      "YOLOv5 ðŸš€ v6.0-6-gd0bfeb3 torch 1.9.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model Summary: 224 layers, 7080880 parameters, 0 gradients\n",
      "\u001b[34m\u001b[1mtest: \u001b[0mScanning 'DeepFashion2/df2_all/labels/test' images and labels...4383 found\u001b[0m\n",
      "\u001b[34m\u001b[1mtest: \u001b[0mNew cache created: DeepFashion2/df2_all/labels/test.cache\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       4383       4383       0.84      0.897      0.908       0.78\n",
      "    short sleeve top       4383        393      0.735       0.73      0.802      0.685\n",
      "     long sleeve top       4383        397      0.754      0.761      0.788      0.631\n",
      "            trousers       4383        400      0.855      0.948      0.964      0.841\n",
      "              shorts       4383        398      0.794      0.922      0.915      0.795\n",
      "  short sleeve dress       4383        400      0.892      0.865      0.922      0.804\n",
      " long sleeve outwear       4383        399      0.927      0.925      0.956      0.778\n",
      "               skirt       4383        396      0.719      0.873      0.818      0.712\n",
      "          vest dress       4383        400      0.918      0.951      0.965       0.85\n",
      "                vest       4383        400      0.853      0.927      0.933      0.774\n",
      "   long sleeve dress       4383        400       0.84      0.968      0.943       0.84\n",
      "         sling dress       4383        400      0.946      0.993       0.98      0.866\n",
      "Speed: 0.4ms pre-process, 226.9ms inference, 0.5ms NMS per image at shape (16, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov5/runs/val/exp6\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python yolov5/val.py --batch-size 16 --data fashion_all_test_1.yaml --weights ./DeepFashion2/bcj_experiments/df2_all/exp2/weights/best.pt --img 640 --task test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "radical-porcelain",
   "metadata": {},
   "outputs": [],
   "source": [
    "#started-21:56, eta-22:05"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "continued-executive",
   "metadata": {},
   "source": [
    "### Model Test 11.B\n",
    "\n",
    "- Model: DF2-trained 11-class model\n",
    "- Dataset:  DF2-Test-1.  Composed of random sample from Train data.  All data in this set is guaranteed to have not been used in training, except for the category 'sling dress'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fixed-surname",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mdata=/Users/blairjones/Desktop/w210/yolov5/data/fashion_all_test_2.yaml, weights=['./DeepFashion2/bcj_experiments/df2_all/exp2/weights/best.pt'], batch_size=16, imgsz=640, conf_thres=0.001, iou_thres=0.6, task=test, device=, single_cls=False, augment=False, verbose=False, save_txt=False, save_hybrid=False, save_conf=False, save_json=False, project=yolov5/runs/val, name=exp, exist_ok=False, half=False\n",
      "YOLOv5 ðŸš€ v6.0-6-gd0bfeb3 torch 1.9.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model Summary: 224 layers, 7080880 parameters, 0 gradients\n",
      "\u001b[34m\u001b[1mtest: \u001b[0mScanning 'DeepFashion2/df2_all/labels/test_2' images and labels...4364 fou\u001b[0m\n",
      "\u001b[34m\u001b[1mtest: \u001b[0mNew cache created: DeepFashion2/df2_all/labels/test_2.cache\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       4364       4364      0.796      0.864      0.881      0.746\n",
      "    short sleeve top       4364        394      0.682      0.736      0.776      0.646\n",
      "     long sleeve top       4364        397      0.695      0.729      0.777      0.631\n",
      "            trousers       4364        400       0.86      0.934      0.961      0.831\n",
      "              shorts       4364        397       0.78       0.89      0.903      0.784\n",
      "  short sleeve dress       4364        400      0.803      0.813      0.867      0.746\n",
      " long sleeve outwear       4364        400      0.868      0.889      0.922       0.72\n",
      "               skirt       4364        397      0.686      0.839      0.793      0.683\n",
      "          vest dress       4364        400      0.865      0.892      0.931      0.811\n",
      "                vest       4364        400      0.845      0.887      0.925      0.744\n",
      "   long sleeve dress       4364        379      0.775      0.894      0.873      0.764\n",
      "         sling dress       4364        400        0.9      0.995      0.966      0.848\n",
      "Speed: 0.4ms pre-process, 245.6ms inference, 0.5ms NMS per image at shape (16, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov5/runs/val/exp8\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python yolov5/val.py --batch-size 16 --data fashion_all_test_2.yaml --weights ./DeepFashion2/bcj_experiments/df2_all/exp2/weights/best.pt --img 640 --task test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "excessive-weight",
   "metadata": {},
   "outputs": [],
   "source": [
    "#started-09:02, finish-09:22"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
