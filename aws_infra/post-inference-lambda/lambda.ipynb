{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 423,
   "id": "81b3c541",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sagemaker_raw_output = \"{'source-ref': 'TBD', 'num-detected-objects': 1, 'bounding-box-attribute-name': {'image_size': [{'width': 640, 'height': 480, 'depth': 3}], 'annotations': [{'class_id': 0, 'left': 140, 'top': 129, 'width': 220, 'height': 286}]}, 'bounding-box-attribute-name-metadata': {'objects': [{'confidence': 0.63}], 'class-map': {'0': 'short sleeve top'}, 'type': 'descriptiveworld/object-detection', 'human-annotated': 'no', 'creation-date': '2021-11-16 01:47:10.657644', 'job-name': 'descriptive_world_identify_garments'}}\"\n",
    "sagemaker_raw_output = {'sageMakerOutput': 'eyJzb3VyY2UtcmVmIjogIlRCRCIsICJudW0tZGV0ZWN0ZWQtb2JqZWN0cyI6IDEsICJib3VuZGluZy1ib3gtYXR0cmlidXRlLW5hbWUiOiB7ImltYWdlX3NpemUiOiBbeyJ3aWR0aCI6IDY0MCwgImhlaWdodCI6IDQ4MCwgImRlcHRoIjogM31dLCAiYW5ub3RhdGlvbnMiOiBbeyJjbGFzc19pZCI6IDAsICJsZWZ0IjogMTQwLCAidG9wIjogMTI5LCAid2lkdGgiOiAyMjAsICJoZWlnaHQiOiAyODZ9XX0sICJib3VuZGluZy1ib3gtYXR0cmlidXRlLW5hbWUtbWV0YWRhdGEiOiB7Im9iamVjdHMiOiBbeyJjb25maWRlbmNlIjogMC42M31dLCAiY2xhc3MtbWFwIjogeyIwIjogInNob3J0IHNsZWV2ZSB0b3AifSwgInR5cGUiOiAiZGVzY3JpcHRpdmV3b3JsZC9vYmplY3QtZGV0ZWN0aW9uIiwgImh1bWFuLWFubm90YXRlZCI6ICJubyIsICJjcmVhdGlvbi1kYXRlIjogIjIwMjEtMTEtMTYgMDE6NDc6MTAuNjU3NjQ0IiwgImpvYi1uYW1lIjogImRlc2NyaXB0aXZlX3dvcmxkX2lkZW50aWZ5X2dhcm1lbnRzIn19', 'streamName': 'descriptiveworld-demo-kvs', 'frameMetaData': 'Frame(trackNumber=1, timeCode=0, keyFrame=true, invisible=false, discardable=false, lacing=NO)', 'fragmentMetaData': 'FragmentMetadata(fragmentNumberString=91343852333183046666493290777218913219824769829, serverSideTimestampMillis=1637008916339, producerSideTimestampMillis=1637008903613, fragmentNumber=91343852333183046666493290777218913219824769829, success=true, errorId=0, errorCode=null, millisBehindNow=OptionalLong[18312650], continuationToken=Optional[91343852333183046666493290777218913219824769829])'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "id": "6c3cb4ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import base64\n",
    "import json\n",
    "import boto3\n",
    "import os\n",
    "from botocore.exceptions import ClientError\n",
    "\n",
    "# set threshold for confidence\n",
    "threshold = 0.75\n",
    "            \n",
    "def lambda_handler(event, context):\n",
    "    for record in event['Records']:\n",
    "        ###payload = base64.b64decode(record['kinesis']['data'])\n",
    "        #Get Json format of Kinesis Data Stream Output\n",
    "        ###result = json.loads(payload)\n",
    "        result = sagemaker_raw_output\n",
    "        # debug\n",
    "        ###print(\"Raw Results:\", result)\n",
    "        #Get FragmentMetaData\n",
    "        fragment = result['fragmentMetaData']\n",
    "        print(\"fragment: \" + fragment + \"\\n\")\n",
    "        #Get FrameMetaData\n",
    "        frame = result['frameMetaData']\n",
    "        print(\"frame: \" + frame + \"\\n\")\n",
    "        #Get StreamName\n",
    "        streamName = result['streamName']\n",
    "        print(\"streamName: \" + streamName + \"\\n\")\n",
    "        #Get SageMaker response and decode\n",
    "        sageMakerOutput = json.loads(base64.b64decode(result['sageMakerOutput']))\n",
    "        # Parse JSON into an object with attributes corresponding to dict keys.\n",
    "        print(\"sagemaker raw output: \" + str(sageMakerOutput))\n",
    "        sageMakerOutput = json.loads('{\"source-ref\": \"TBD\",\"num-detected-objects\": 3,\"bounding-box-attribute-name\":{\"image_size\": [{\"width\": 640, \"height\": 480, \"depth\": 3}],\"annotations\":[{\"class_id\": 0, \"left\": 140, \"top\": 129, \"width\": 220, \"height\": 286},{\"class_id\": 1, \"left\": 140, \"top\": 129, \"width\": 220, \"height\": 286},{\"class_id\": 1, \"left\": 140, \"top\": 129, \"width\": 220, \"height\": 286}]},\"bounding-box-attribute-name-metadata\":{\"objects\":[{\"confidence\": 0.63},{\"confidence\": 0.55},{\"confidence\": 0.75}],\"class-map\":{\"0\": \"short sleeve top\",\"1\": \"trousers\"},\"type\": \"descriptiveworld/object-detection\",\"human-annotated\": \"no\",\"creation-date\": \"2021-11-16 01:47:10.657644\",\"job-name\": \"descriptive_world_identify_garments\"}}')\n",
    "        # First check to see if this is a new image, if not we don't do any inference\n",
    "        # TODO\n",
    " \n",
    "        # store the number of detected objects\n",
    "        numObjects = int(sageMakerOutput['num-detected-objects'])\n",
    "        \n",
    "        # IF we have no objects, nothing left to do, let's end this lambda\n",
    "        if (numObjects == 0):\n",
    "            return None\n",
    "        \n",
    "        # although image size can appear with every object identification, we know it will always be the same\n",
    "        imageSize = dict(sageMakerOutput['bounding-box-attribute-name']['image_size'][0])\n",
    "        imageSizeHeight = imageSize['height']\n",
    "        imageSizeWidth = imageSize['width']\n",
    "        imageSizeDepth = imageSize['depth']\n",
    "    \n",
    "        # indices are not unique for foundObjects and boundingBoxConf\n",
    "        # we will convert them to array of lists\n",
    "        foundObjects = json.loads(json.dumps(sageMakerOutput['bounding-box-attribute-name']['annotations']))\n",
    "        boundingBoxConfs = json.loads(json.dumps(sageMakerOutput['bounding-box-attribute-name-metadata']['objects']))\n",
    "        \n",
    "        # comes in as a list enclosed in {} let's convert to a dictionary since indices are unique\n",
    "        boundingBoxClassMap = json.loads(json.dumps(sageMakerOutput['bounding-box-attribute-name-metadata']['class-map']))\n",
    "    \n",
    "        # debug\n",
    "        print (\"Number of Objects:\", numObjects, \"\\nImage Size:\", imageSize)\n",
    "        print(\"Found Objects:\", foundObjects, \"\\nBB Conf:\", boundingBoxConfs, \"\\nBB Class Map:\", boundingBoxClassMap, \"\\n\")\n",
    "        \n",
    "        polly_sentence = \"The following items are in front of you\"\n",
    "        # iterate over each one of the object found\n",
    "        # This is the 'annotations', 'bounding-box-attribute-name-metadata'\n",
    "        for i in range(0,numObjects):\n",
    "            foundObject = foundObjects[i]\n",
    "            boundingBoxConf = boundingBoxConfs[i]\n",
    "            foundObjectClass_ID = foundObjects[i]['class_id']\n",
    "            foundOjbectClassName = boundingBoxClassMap[str(foundObjectClass_ID)]\n",
    "            print(\"Found Object:\", foundObject, \"Class Name:\", foundOjbectClassName, \"Confidence\", boundingBoxConf, \"\\n\")\n",
    "            # append to polly sentence\n",
    "            polly_sentence += \", \" + foundOjbectClassName\n",
    "\n",
    "        # Compose string for Amazon Polly\n",
    "        print(polly_sentence)\n",
    "        # Send string to amazon polly API to generate MP3\n",
    "        \n",
    "        # Draw bounding boxes on image\n",
    "        # TODO \n",
    "        \n",
    "        \n",
    "    return 'Successfully processed {} records.'.format(len(event['Records']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "id": "a472ad50",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import base64\n",
    "import json\n",
    "import boto3\n",
    "import os\n",
    "from botocore.exceptions import ClientError\n",
    "from datetime import datetime\n",
    "import time\n",
    "import calendar\n",
    "import re\n",
    "\n",
    "# set threshold for confidence\n",
    "threshold = 0.75\n",
    "# set region\n",
    "region = \"us-west-2\"\n",
    "stream_out_polly_name = \"descriptive-demo-Post-Inference-Polly\"\n",
    "stream_out_polly_shards = 1\n",
    "stream_out_imagebb_name = \"descriptive-demo-Post-Inference-Image-Bounding-Box\"\n",
    "stream_out_imagebb_shards = 1\n",
    "# setup kinesis client\n",
    "kinesis_client = boto3.client('kinesis',region_name=region)\n",
    "\n",
    "# method to write to the kinesis data stream\n",
    "def put_to_stream(stream_out_name, data):\n",
    "    timestamp = calendar.timegm(datetime.utcnow().timetuple())\n",
    "    \n",
    "    # JSON formatted payload\n",
    "    payload = {\n",
    "        'timestamp': int(timestamp),\n",
    "        'data': data\n",
    "    }\n",
    "    print (\"Payload for Kinesis DS: \", payload)\n",
    "    put_response = kinesis_client.put_record(\n",
    "        StreamName=stream_out_name,\n",
    "        Data=json.dumps(payload),\n",
    "        PartitionKey='inference')\n",
    "        \n",
    "# our  entry point            \n",
    "def lambda_handler(event, context):\n",
    "    for record in event['Records']:\n",
    "        ###payload = base64.b64decode(record['kinesis']['data'])\n",
    "        #Get Json format of Kinesis Data Stream Output\n",
    "        ###result = json.loads(payload)\n",
    "        result = sagemaker_raw_output\n",
    "\n",
    "        print(\"START OF EXECUTION\")\n",
    "        # debug\n",
    "        print(\"Raw Results:\", result)\n",
    "        #Get FragmentMetaData\n",
    "        fragment = result['fragmentMetaData']\n",
    "        print(\"fragment: \" + fragment + \"\\n\")\n",
    "        #Get FrameMetaData\n",
    "        frame = result['frameMetaData']\n",
    "        print(\"frame: \" + frame + \"\\n\")\n",
    "        #Get StreamName\n",
    "        streamName = result['streamName']\n",
    "        print(\"streamName: \" + streamName + \"\\n\")\n",
    "        #Get SageMaker response and decode\n",
    "        sageMakerOutput = json.loads(base64.b64decode(result['sageMakerOutput']))\n",
    "        # Parse JSON into an object with attributes corresponding to dict keys.\n",
    "        print(\"sagemaker raw output: \" + str(sageMakerOutput))\n",
    "        # First check to see if this is a new image, if not we don't do any inference\n",
    "        # TODO\n",
    "        \n",
    "        # store the number of detected objects\n",
    "        numObjects = int(sageMakerOutput['num-detected-objects'])\n",
    "        \n",
    "        # IF we have no objects, nothing left to do, let's end this lambda\n",
    "        if (numObjects == 0):\n",
    "            print(\"NO OBJECTS DETECTED, EXITING...\")\n",
    "            print(\"END OF EXECUTION\")\n",
    "            return None\n",
    "        \n",
    "        # record the source (should be full URI to image in S3)\n",
    "        sourceRef = str(sageMakerOutput['source-ref'])\n",
    "        \n",
    "        # extract fragment number \n",
    "        fragmentNumber = re.search(r'^.*?\\bfragmentNumber=(\\d+),.*', fragment).group(1)\n",
    "        \n",
    "        # although image size can appear with every object identification, we know it will always be the same\n",
    "        imageSize = dict(sageMakerOutput['bounding-box-attribute-name']['image_size'][0])\n",
    "        imageSizeHeight = imageSize['height']\n",
    "        imageSizeWidth = imageSize['width']\n",
    "        imageSizeDepth = imageSize['depth']\n",
    "    \n",
    "        # indices are not unique for foundObjects and boundingBoxConf\n",
    "        # we will convert them to array of lists\n",
    "        foundObjects = json.loads(json.dumps(sageMakerOutput['bounding-box-attribute-name']['annotations']))\n",
    "        boundingBoxConfs = json.loads(json.dumps(sageMakerOutput['bounding-box-attribute-name-metadata']['objects']))\n",
    "        \n",
    "        # comes in as a list enclosed in {} let's convert to a dictionary since indices are unique\n",
    "        boundingBoxClassMap = json.loads(json.dumps(sageMakerOutput['bounding-box-attribute-name-metadata']['class-map']))\n",
    "    \n",
    "        # debug\n",
    "        print (\"Number of Objects:\", numObjects, \"\\nImage Size:\", imageSize)\n",
    "        print(\"Found Objects:\", foundObjects, \"\\nBB Conf:\", boundingBoxConfs, \"\\nBB Class Map:\", boundingBoxClassMap, \"\\n\")\n",
    "        \n",
    "        polly_sentence = \"There are \" + str(numObjects) + \" items in front of you\"\n",
    "        objects_detected = '{\"class\": \"'\n",
    "        # iterate over each one of the object found\n",
    "        # This is the 'annotations', 'bounding-box-attribute-name-metadata'\n",
    "        for i in range(0,numObjects):\n",
    "            foundObject = foundObjects[i]\n",
    "            boundingBoxConf = boundingBoxConfs[i]\n",
    "            foundObjectClass_ID = foundObjects[i]['class_id']\n",
    "            foundObjectClassName = boundingBoxClassMap[str(foundObjectClass_ID)]\n",
    "            foundObjectLeft = foundObjects[i]['left']\n",
    "            foundObjectTop = foundObjects[i]['top']\n",
    "            foundObjectWidth = foundObjects[i]['width']\n",
    "            foundObjectHeight = foundObjects[i]['height']\n",
    "            print(\"Found Object:\", foundObject, \"Class Name:\", foundObjectClassName, \"Confidence\", boundingBoxConf, \"\\n\")\n",
    "            # append to polly sentence\n",
    "            polly_sentence += \", \" + foundObjectClassName\n",
    "            # append to objects JSON string\n",
    "            objects_detected += str(foundObjectClassName) + '\", \"confidence\": ' + str(boundingBoxConf['confidence']) + ', \"left\": ' + str(foundObjectLeft) + ', \"top\": ' +  \\\n",
    "                str(foundObjectTop) + ', \"width\": ' + str(foundObjectWidth) + ', \"height\": ' + str(foundObjectHeight)\n",
    "            if (i < numObjects-1):\n",
    "                objects_detected += ', ' \n",
    "\n",
    "        objects_detected += '}'\n",
    "        polly_sentence += \".\"\n",
    "        # reformat objects_detected as JSON\n",
    "        objects_detected = json.loads(objects_detected)\n",
    "        \n",
    "        # Print complete sentence for Amazon Polly\n",
    "        print(polly_sentence)\n",
    "\n",
    "        \n",
    "        # construct JSON for data payload for polly\n",
    "        data_polly = {\n",
    "            'fragment-number': int(fragmentNumber),\n",
    "            'sentence' : polly_sentence\n",
    "        }\n",
    "        \n",
    "        # Now send all data to the kinesis data stream (to be picked up for polly narration)\n",
    "        put_to_stream(stream_out_polly_name, data_polly)\n",
    "        \n",
    "        # construct JSON for data payload for polly\n",
    "        data_imagebb = {\n",
    "            'source-ref': sourceRef,\n",
    "            'fragment-number': int(fragmentNumber),\n",
    "            'num-detected-objects': numObjects,\n",
    "            'image-size': imageSize,\n",
    "            'objects': objects_detected\n",
    "        }\n",
    "        # Now send all data to the kinesis data stream (to be picked up for polly narration)\n",
    "        put_to_stream(stream_out_imagebb_name, data_imagebb)\n",
    "        \n",
    "        print(str(numObjects) + \" OBJECTS DETECTED\")\n",
    "        print(\"END OF EXECUTION\")\n",
    "        \n",
    "    return 'Successfully processed {} records.'.format(len(event['Records']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "id": "362d22af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "START OF EXECUTION\n",
      "Raw Results: {'sageMakerOutput': 'eyJzb3VyY2UtcmVmIjogIlRCRCIsICJudW0tZGV0ZWN0ZWQtb2JqZWN0cyI6IDEsICJib3VuZGluZy1ib3gtYXR0cmlidXRlLW5hbWUiOiB7ImltYWdlX3NpemUiOiBbeyJ3aWR0aCI6IDY0MCwgImhlaWdodCI6IDQ4MCwgImRlcHRoIjogM31dLCAiYW5ub3RhdGlvbnMiOiBbeyJjbGFzc19pZCI6IDAsICJsZWZ0IjogMTQwLCAidG9wIjogMTI5LCAid2lkdGgiOiAyMjAsICJoZWlnaHQiOiAyODZ9XX0sICJib3VuZGluZy1ib3gtYXR0cmlidXRlLW5hbWUtbWV0YWRhdGEiOiB7Im9iamVjdHMiOiBbeyJjb25maWRlbmNlIjogMC42M31dLCAiY2xhc3MtbWFwIjogeyIwIjogInNob3J0IHNsZWV2ZSB0b3AifSwgInR5cGUiOiAiZGVzY3JpcHRpdmV3b3JsZC9vYmplY3QtZGV0ZWN0aW9uIiwgImh1bWFuLWFubm90YXRlZCI6ICJubyIsICJjcmVhdGlvbi1kYXRlIjogIjIwMjEtMTEtMTYgMDE6NDc6MTAuNjU3NjQ0IiwgImpvYi1uYW1lIjogImRlc2NyaXB0aXZlX3dvcmxkX2lkZW50aWZ5X2dhcm1lbnRzIn19', 'streamName': 'descriptiveworld-demo-kvs', 'frameMetaData': 'Frame(trackNumber=1, timeCode=0, keyFrame=true, invisible=false, discardable=false, lacing=NO)', 'fragmentMetaData': 'FragmentMetadata(fragmentNumberString=91343852333183046666493290777218913219824769829, serverSideTimestampMillis=1637008916339, producerSideTimestampMillis=1637008903613, fragmentNumber=91343852333183046666493290777218913219824769829, success=true, errorId=0, errorCode=null, millisBehindNow=OptionalLong[18312650], continuationToken=Optional[91343852333183046666493290777218913219824769829])'}\n",
      "fragment: FragmentMetadata(fragmentNumberString=91343852333183046666493290777218913219824769829, serverSideTimestampMillis=1637008916339, producerSideTimestampMillis=1637008903613, fragmentNumber=91343852333183046666493290777218913219824769829, success=true, errorId=0, errorCode=null, millisBehindNow=OptionalLong[18312650], continuationToken=Optional[91343852333183046666493290777218913219824769829])\n",
      "\n",
      "frame: Frame(trackNumber=1, timeCode=0, keyFrame=true, invisible=false, discardable=false, lacing=NO)\n",
      "\n",
      "streamName: descriptiveworld-demo-kvs\n",
      "\n",
      "sagemaker raw output: {'source-ref': 'TBD', 'num-detected-objects': 1, 'bounding-box-attribute-name': {'image_size': [{'width': 640, 'height': 480, 'depth': 3}], 'annotations': [{'class_id': 0, 'left': 140, 'top': 129, 'width': 220, 'height': 286}]}, 'bounding-box-attribute-name-metadata': {'objects': [{'confidence': 0.63}], 'class-map': {'0': 'short sleeve top'}, 'type': 'descriptiveworld/object-detection', 'human-annotated': 'no', 'creation-date': '2021-11-16 01:47:10.657644', 'job-name': 'descriptive_world_identify_garments'}}\n",
      "Number of Objects: 1 \n",
      "Image Size: {'width': 640, 'height': 480, 'depth': 3}\n",
      "Found Objects: [{'class_id': 0, 'left': 140, 'top': 129, 'width': 220, 'height': 286}] \n",
      "BB Conf: [{'confidence': 0.63}] \n",
      "BB Class Map: {'0': 'short sleeve top'} \n",
      "\n",
      "Found Object: {'class_id': 0, 'left': 140, 'top': 129, 'width': 220, 'height': 286} Class Name: short sleeve top Confidence {'confidence': 0.63} \n",
      "\n",
      "There are 1 items in front of you, short sleeve top.\n",
      "Payload for Kinesis DS:  {'timestamp': 1638127804, 'data': {'fragment-number': 91343852333183046666493290777218913219824769829, 'sentence': 'There are 1 items in front of you, short sleeve top.'}}\n",
      "Payload for Kinesis DS:  {'timestamp': 1638127804, 'data': {'source-ref': 'TBD', 'fragment-number': 91343852333183046666493290777218913219824769829, 'num-detected-objects': 1, 'image-size': {'width': 640, 'height': 480, 'depth': 3}, 'objects': {'class': 'short sleeve top', 'confidence': 0.63, 'left': 140, 'top': 129, 'width': 220, 'height': 286}}}\n",
      "1 OBJECTS DETECTED\n",
      "END OF EXECUTION\n",
      "Successfully processed 1 records.\n"
     ]
    }
   ],
   "source": [
    "sm_event = dict()\n",
    "sm_event['Records'] = ['kinesis']\n",
    "records_processed = (lambda_handler(sm_event, \"\"))\n",
    "print(records_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fac4cc7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c825a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77b9d9a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0e10c73",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
